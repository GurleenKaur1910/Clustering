{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, MeanShift\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "# Load Dataset (Wine Dataset from UCI)\n",
        "data = load_wine()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Define Preprocessing Techniques\n",
        "def apply_preprocessing(X, method):\n",
        "    if method == \"No Data Processing\":\n",
        "        return X\n",
        "    elif method == \"Using Normalization\":\n",
        "        return pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
        "    elif method == \"Using Transform\":\n",
        "        return pd.DataFrame(np.log1p(X), columns=X.columns)  # Log Transform\n",
        "    elif method == \"Using PCA\":\n",
        "        return pd.DataFrame(PCA(n_components=5).fit_transform(X))  # Reduce to 5 components\n",
        "    elif method == \"Using T+N\":\n",
        "        X_transformed = np.log1p(X)\n",
        "        return pd.DataFrame(StandardScaler().fit_transform(X_transformed), columns=X.columns)\n",
        "    elif method == \"T+N+PCA\":\n",
        "        X_transformed = np.log1p(X)\n",
        "        X_normalized = StandardScaler().fit_transform(X_transformed)\n",
        "        return pd.DataFrame(PCA(n_components=5).fit_transform(X_normalized))\n",
        "\n",
        "# Clustering Algorithms\n",
        "def perform_clustering(X, n_clusters, method):\n",
        "    if method == \"K-Means\":\n",
        "        model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    elif method == \"Hierarchical\":\n",
        "        model = AgglomerativeClustering(n_clusters=n_clusters)\n",
        "    elif method == \"Mean-Shift\":\n",
        "        model = MeanShift()\n",
        "        return model.fit_predict(X)  # No cluster parameter for Mean-Shift\n",
        "    return model.fit_predict(X)\n",
        "\n",
        "# Define evaluation metrics\n",
        "def evaluate_clustering(X, labels):\n",
        "    if len(set(labels)) == 1:  # Avoid error when only one cluster is detected\n",
        "        return np.nan, np.nan, np.nan\n",
        "    silhouette = silhouette_score(X, labels)\n",
        "    calinski = calinski_harabasz_score(X, labels)\n",
        "    davies = davies_bouldin_score(X, labels)\n",
        "    return silhouette, calinski, davies\n",
        "\n",
        "# Preprocessing Methods\n",
        "preprocessing_methods = [\n",
        "    \"No Data Processing\",\n",
        "    \"Using Normalization\",\n",
        "    \"Using Transform\",\n",
        "    \"Using PCA\",\n",
        "    \"Using T+N\",\n",
        "    \"T+N+PCA\"\n",
        "]\n",
        "\n",
        "# Clustering Techniques\n",
        "clustering_methods = [\"K-Means\", \"Hierarchical\", \"Mean-Shift\"]\n",
        "\n",
        "# Cluster sizes\n",
        "cluster_counts = [3, 4]  # Adjust this list if you want more cluster counts\n",
        "\n",
        "# Perform clustering and store results\n",
        "for cluster_method in clustering_methods:\n",
        "    print(f\"\\n\\nUsing {cluster_method} Clustering\\n\")\n",
        "\n",
        "    # Data structure to store results\n",
        "    results_dict = {}\n",
        "\n",
        "    for preprocessing in preprocessing_methods:\n",
        "        for c in cluster_counts:\n",
        "            X_processed = apply_preprocessing(X, preprocessing)\n",
        "\n",
        "            # Perform clustering\n",
        "            if cluster_method == \"Mean-Shift\":\n",
        "                labels = perform_clustering(X_processed, None, cluster_method)\n",
        "            else:\n",
        "                labels = perform_clustering(X_processed, c, cluster_method)\n",
        "\n",
        "            # Compute metrics\n",
        "            silhouette, calinski, davies = evaluate_clustering(X_processed, labels)\n",
        "\n",
        "            # Store results\n",
        "            results_dict[f\"{preprocessing} (c={c})\"] = [silhouette, calinski, davies]\n",
        "\n",
        "    # Convert dictionary to DataFrame\n",
        "    df_results = pd.DataFrame(results_dict, index=[\"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"])\n",
        "    print(df_results.to_string(index=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yanRklxyPcKh",
        "outputId": "7c528bbc-3b17-477e-e599-045ce4235a58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Using K-Means Clustering\n",
            "\n",
            "                   No Data Processing (c=3)  No Data Processing (c=4)  Using Normalization (c=3)  Using Normalization (c=4)  Using Transform (c=3)  Using Transform (c=4)  Using PCA (c=3)  Using PCA (c=4)  Using T+N (c=3)  Using T+N (c=4)  T+N+PCA (c=3)  T+N+PCA (c=4)\n",
            "Silhouette                         0.571138                  0.562032                   0.284859                   0.260170               0.391821               0.337233         0.571237         0.562153         0.306927         0.295069       0.391030       0.378766\n",
            "Calinski-Harabasz                561.815658                708.086676                  70.940008                  56.181355             120.025162              95.945856       561.877765       708.226941        76.019395        59.827978     116.347340      95.294050\n",
            "Davies-Bouldin                     0.534243                  0.544345                   1.389188                   1.796892               1.018898               1.399817         0.534133         0.544236         1.337403         1.647088       1.052546       1.277518\n",
            "\n",
            "\n",
            "Using Hierarchical Clustering\n",
            "\n",
            "                   No Data Processing (c=3)  No Data Processing (c=4)  Using Normalization (c=3)  Using Normalization (c=4)  Using Transform (c=3)  Using Transform (c=4)  Using PCA (c=3)  Using PCA (c=4)  Using T+N (c=3)  Using T+N (c=4)  T+N+PCA (c=3)  T+N+PCA (c=4)\n",
            "Silhouette                         0.564480                  0.560673                   0.277444                   0.225837               0.377289               0.314883         0.564578         0.560785         0.295571         0.273862       0.365427       0.360462\n",
            "Calinski-Harabasz                552.851712                670.625991                  67.647468                  51.464146             111.985609              87.370936       552.912224       670.750768        73.153378        56.698711     105.314777      88.853002\n",
            "Davies-Bouldin                     0.535734                  0.553574                   1.418592                   1.788651               1.072687               1.473524         0.535619         0.553457         1.363160         1.790584       1.100002       1.362499\n",
            "\n",
            "\n",
            "Using Mean-Shift Clustering\n",
            "\n",
            "                   No Data Processing (c=3)  No Data Processing (c=4)  Using Normalization (c=3)  Using Normalization (c=4)  Using Transform (c=3)  Using Transform (c=4)  Using PCA (c=3)  Using PCA (c=4)  Using T+N (c=3)  Using T+N (c=4)  T+N+PCA (c=3)  T+N+PCA (c=4)\n",
            "Silhouette                         0.502492                  0.502492                   0.224476                   0.224476               0.317306               0.317306         0.502558         0.502558         0.356037         0.356037       0.312598       0.312598\n",
            "Calinski-Harabasz                454.058943                454.058943                   6.435434                   6.435434              81.569543              81.569543       454.101494       454.101494         3.757702         3.757702      53.147267      53.147267\n",
            "Davies-Bouldin                     0.556150                  0.556150                   1.320059                   1.320059               1.283705               1.283705         0.556059         0.556059         0.503305         0.503305       1.094237       1.094237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADZPyMtnQQqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}